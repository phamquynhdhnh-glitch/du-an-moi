# C·∫ßn c√†i ƒë·∫∑t:
# pip install streamlit pandas numpy_financial google-genai python-docx

import streamlit as st
import pandas as pd
import numpy as np
import numpy_financial as npf # Th∆∞ vi·ªán t√≠nh to√°n t√†i ch√≠nh nh∆∞ NPV, IRR
from google import genai
from google.genai.errors import APIError
from docx import Document
import io
import json

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="App ƒê√°nh gi√° D·ª± √°n ƒê·∫ßu t∆∞ (AI)",
    layout="wide"
)

st.title("·ª®ng d·ª•ng ƒê√°nh gi√° D·ª± √°n ƒê·∫ßu t∆∞ üìà")
st.markdown("S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ file Word (.docx), x√¢y d·ª±ng d√≤ng ti·ªÅn v√† t√≠nh to√°n hi·ªáu qu·∫£ d·ª± √°n.")

# --- Thi·∫øt l·∫≠p API Key ---
# ƒê·∫£m b·∫£o b·∫°n ƒë√£ c·∫•u h√¨nh 'GEMINI_API_KEY' trong Streamlit Secrets
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    API_KEY = None
    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API 'GEMINI_API_KEY'. Vui l√≤ng c·∫•u h√¨nh trong Streamlit Secrets.")

# --- 1. H√†m Tr√≠ch xu·∫•t D·ªØ li·ªáu t·ª´ Word b·∫±ng AI ---

def extract_text_from_docx(file):
    """ƒê·ªçc v√† tr√≠ch xu·∫•t to√†n b·ªô vƒÉn b·∫£n t·ª´ file Word ƒë√£ upload."""
    try:
        # docx.Document() c·∫ßn m·ªôt ƒë·ªëi t∆∞·ª£ng file-like
        document = Document(io.BytesIO(file.read()))
        text = "\n".join([paragraph.text for paragraph in document.paragraphs if paragraph.text.strip()])
        return text
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file DOCX: {e}")
        return None

def ai_extract_financial_parameters(document_text, api_key):
    """
    S·ª≠ d·ª•ng Gemini AI v·ªõi JSON Schema ƒë·ªÉ tr√≠ch xu·∫•t c√°c th√¥ng s·ªë t√†i ch√≠nh.
    """
    if not api_key:
        return None, "L·ªói API Key: Vui l√≤ng cung c·∫•p Kh√≥a API Gemini."

    client = genai.Client(api_key=api_key)
    model_name = 'gemini-2.5-flash'
    
    # ƒê·ªãnh nghƒ©a c·∫•u tr√∫c JSON c·∫ßn tr√≠ch xu·∫•t (Task 1)
    response_schema = {
        "type": "OBJECT",
        "properties": {
            "V·ªën_ƒê·∫ßu_T∆∞": {"type": "NUMBER", "description": "T·ªïng v·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu c·ªßa d·ª± √°n (lu√¥n l√† s·ªë d∆∞∆°ng, ƒë∆°n v·ªã tri·ªáu/t·ª∑ ƒë·ªìng)."},
            "D√≤ng_ƒê·ªùi_D·ª±_√Ån": {"type": "INTEGER", "description": "S·ªë nƒÉm ho·∫°t ƒë·ªông c·ªßa d·ª± √°n (t·ªëi ƒëa 20 nƒÉm)."},
            "Doanh_Thu_H√†ng_NƒÉm": {"type": "NUMBER", "description": "Doanh thu ∆∞·ªõc t√≠nh h√†ng nƒÉm (Gi·∫£ ƒë·ªãnh c·ªë ƒë·ªãnh, ƒë∆°n v·ªã tri·ªáu/t·ª∑ ƒë·ªìng)."},
            "Chi_Ph√≠_H√†ng_NƒÉm": {"type": "NUMBER", "description": "T·ªïng chi ph√≠ ho·∫°t ƒë·ªông ∆∞·ªõc t√≠nh h√†ng nƒÉm (ch∆∞a bao g·ªìm Kh·∫•u hao v√† L√£i vay, ƒë∆°n v·ªã tri·ªáu/t·ª∑ ƒë·ªìng)."},
            "WACC": {"type": "NUMBER", "description": "T·ª∑ l·ªá chi ph√≠ s·ª≠ d·ª•ng v·ªën (WACC) d∆∞·ªõi d·∫°ng th·∫≠p ph√¢n (v√≠ d·ª•: 0.10 cho 10%)."},
            "Thu·∫ø_Su·∫•t": {"type": "NUMBER", "description": "Thu·∫ø su·∫•t thu nh·∫≠p doanh nghi·ªáp d∆∞·ªõi d·∫°ng th·∫≠p ph√¢n (v√≠ d·ª•: 0.20 cho 20%)."}
        },
        "required": ["V·ªën_ƒê·∫ßu_T∆∞", "D√≤ng_ƒê·ªùi_D·ª±_√Ån", "Doanh_Thu_H√†ng_NƒÉm", "Chi_Ph√≠_H√†ng_NƒÉm", "WACC", "Thu·∫ø_Su·∫•t"]
    }
    
    system_prompt = (
        "B·∫°n l√† m·ªôt chuy√™n gia t√†i ch√≠nh. H√£y ƒë·ªçc n·ªôi dung vƒÉn b·∫£n kinh doanh b√™n d∆∞·ªõi v√† tr√≠ch xu·∫•t CH√çNH X√ÅC "
        "c√°c th√¥ng s·ªë t√†i ch√≠nh v√†o c·∫•u tr√∫c JSON ƒë∆∞·ª£c cung c·∫•p. T·∫•t c·∫£ c√°c gi√° tr·ªã (tr·ª´ v·ªën v√† tu·ªïi th·ªç) ph·∫£i ƒë∆∞·ª£c "
        "chuy·ªÉn ƒë·ªïi th√†nh S·ªê NGUY√äN/S·ªê TH·ª∞C, KH√îNG ƒë·ªÉ d·∫•u ph·∫©y, KH√îNG c√≥ ƒë∆°n v·ªã (v√≠ d·ª•: '1000' ch·ª© kh√¥ng ph·∫£i '1,000 t·ª∑'). "
        "Chi ph√≠ ƒë∆∞·ª£c hi·ªÉu l√† chi ph√≠ ho·∫°t ƒë·ªông kh√¥ng bao g·ªìm kh·∫•u hao v√† l√£i vay."
    )

    prompt = f"Tr√≠ch xu·∫•t c√°c th√¥ng s·ªë t√†i ch√≠nh t·ª´ b√°o c√°o n√†y: \n\n{document_text}"

    try:
        response = client.models.generate_content(
            model=model_name,
            contents=prompt,
            config={
                "system_instruction": system_prompt,
                "response_mime_type": "application/json",
                "response_schema": response_schema
            }
        )
        # Parse JSON output
        extracted_data = json.loads(response.text)
        return extracted_data, "Tr√≠ch xu·∫•t d·ªØ li·ªáu th√†nh c√¥ng."

    except APIError as e:
        return None, f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt l·ªói: {e}"
    except Exception as e:
        # Bao g·ªìm l·ªói parsing JSON
        st.error(f"Ph·∫£n h·ªìi c·ªßa AI kh√¥ng h·ª£p l·ªá ho·∫∑c l·ªói x·ª≠ l√Ω JSON: {response.text}")
        return None, f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

# --- 2. H√†m X√¢y d·ª±ng B·∫£ng D√≤ng Ti·ªÅn & 3. T√≠nh to√°n Ch·ªâ s·ªë ---

# Kh·∫•u hao ƒë∆∞·ªùng th·∫≥ng (Gi·∫£ ƒë·ªãnh TSLN = 0)
def calculate_depreciation(investment, lifespan):
    return investment / lifespan

def build_cash_flow_and_calculate_metrics(params):
    """
    X√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn v√† t√≠nh to√°n c√°c ch·ªâ s·ªë hi·ªáu qu·∫£ d·ª± √°n. (Task 2 & 3)
    """
    # L·∫•y th√¥ng s·ªë
    I0 = params['V·ªën_ƒê·∫ßu_T∆∞']
    N = params['D√≤ng_ƒê·ªùi_D·ª±_√Ån']
    R = params['Doanh_Thu_H√†ng_NƒÉm']
    C = params['Chi_Ph√≠_H√†ng_NƒÉm']
    WACC = params['WACC']
    T = params['Thu·∫ø_Su·∫•t']
    
    D = calculate_depreciation(I0, N) # Kh·∫•u hao h√†ng nƒÉm

    # X√¢y d·ª±ng D√≤ng Ti·ªÅn
    years = np.arange(0, N + 1)
    
    # Kh·ªüi t·∫°o c√°c d√≤ng ti·ªÅn b·∫±ng 0
    df = pd.DataFrame(index=years)
    df.index.name = 'NƒÉm'
    
    # 1. D√≤ng Doanh thu, Chi ph√≠, Kh·∫•u hao
    df['Doanh thu (R)'] = R
    df['Chi ph√≠ (C)'] = C
    df['Kh·∫•u hao (D)'] = D
    
    # 2. L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø v√† l√£i vay (EBT)
    df['L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø (EBT)'] = df['Doanh thu (R)'] - df['Chi ph√≠ (C)'] - df['Kh·∫•u hao (D)']
    
    # 3. Thu·∫ø (Tax)
    df['Thu·∫ø (Tax)'] = np.where(df['L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø (EBT)'] > 0, df['L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø (EBT)'] * T, 0)
    
    # 4. D√≤ng ti·ªÅn r√≤ng t·ª´ ho·∫°t ƒë·ªông (OCF)
    # OCF = EBT - Tax + D
    df['OCF'] = df['L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø (EBT)'] - df['Thu·∫ø (Tax)'] + df['Kh·∫•u hao (D)']
    
    # 5. D√≤ng ti·ªÅn r√≤ng c·ªßa d·ª± √°n (NCF)
    df['NCF'] = df['OCF']
    df.loc[0, 'NCF'] = -I0 # V·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu (Outflow)

    # --- T√≠nh to√°n Ch·ªâ s·ªë Hi·ªáu qu·∫£ (Task 3) ---
    cash_flows = df['NCF'].tolist()
    
    # 1. NPV
    npv = npf.npv(WACC, cash_flows)
    
    # 2. IRR
    try:
        irr = npf.irr(cash_flows)
    except:
        irr = np.nan # NaN n·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c IRR

    # 3. Payback Period (PP) - Th·ªùi gian ho√†n v·ªën
    cumulative_cf = np.cumsum(cash_flows)
    pp_year = np.argmax(cumulative_cf >= 0)
    pp_fraction = (cumulative_cf[pp_year-1] * -1) / cash_flows[pp_year]
    pp = pp_year - 1 + pp_fraction if pp_year > 0 else 0

    # 4. Discounted Payback Period (DPP) - Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u
    discounted_cf = [cf / ((1 + WACC) ** year) for year, cf in enumerate(cash_flows)]
    cumulative_dcf = np.cumsum(discounted_cf)
    dpp_year = np.argmax(cumulative_dcf >= 0)
    dpp_fraction = (cumulative_dcf[dpp_year-1] * -1) / discounted_cf[dpp_year]
    dpp = dpp_year - 1 + dpp_fraction if dpp_year > 0 else 0

    metrics = {
        'NPV': npv,
        'IRR': irr,
        'PP': pp,
        'DPP': dpp,
        'D√≤ng ƒê·ªùi D·ª± √Ån': N
    }
    
    return df, metrics

# --- 4. H√†m Ph√¢n t√≠ch AI c√°c Ch·ªâ s·ªë Hi·ªáu qu·∫£ ---

def ai_analyze_metrics(metrics, api_key):
    """G·ª≠i c√°c ch·ªâ s·ªë NPV, IRR, PP, DPP ƒë·∫øn AI ƒë·ªÉ ph√¢n t√≠ch."""
    if not api_key:
        return "L·ªói API Key: Vui l√≤ng cung c·∫•p Kh√≥a API Gemini."

    client = genai.Client(api_key=api_key)
    model_name = 'gemini-2.5-flash'
    
    metrics_str = "\n".join([f"- {k}: {v:.2f}" for k, v in metrics.items() if k not in ['D√≤ng ƒê·ªùi D·ª± √Ån']])
    
    system_prompt = (
        "B·∫°n l√† m·ªôt nh√† t∆∞ v·∫•n t√†i ch√≠nh c·∫•p cao chuy√™n v·ªÅ ƒë√°nh gi√° d·ª± √°n ƒë·∫ßu t∆∞. "
        "Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch c√°c ch·ªâ s·ªë hi·ªáu qu·∫£ d·ª± √°n (NPV, IRR, PP, DPP) v√† "
        "ƒë∆∞a ra nh·∫≠n ƒë·ªãnh r√µ r√†ng v·ªÅ t√≠nh kh·∫£ thi, ƒë·ªô h·∫•p d·∫´n, v√† r·ªßi ro c·ªßa d·ª± √°n. "
        "Ph·∫£n h·ªìi ph·∫£i: 1) Nh·∫≠n ƒë·ªãnh NPV v√† IRR (d·ª± √°n c√≥ n√™n ƒë∆∞·ª£c ch·∫•p nh·∫≠n kh√¥ng?), "
        "2) So s√°nh IRR v·ªõi WACC, 3) ƒê√°nh gi√° th·ªùi gian ho√†n v·ªën (PP/DPP) so v·ªõi tu·ªïi th·ªç d·ª± √°n. "
        "Tr√¨nh b√†y k·∫øt qu·∫£ d∆∞·ªõi 3 ƒëo·∫°n vƒÉn ng·∫Øn g·ªçn b·∫±ng ti·∫øng Vi·ªát."
    )

    prompt = f"""
    H√£y ph√¢n t√≠ch chi ti·∫øt c√°c ch·ªâ s·ªë hi·ªáu qu·∫£ sau c·ªßa d·ª± √°n:
    
    - Chi ph√≠ s·ª≠ d·ª•ng v·ªën (WACC): {metrics['WACC']:.2%}
    - D√≤ng ƒë·ªùi d·ª± √°n (N): {metrics['D√≤ng ƒê·ªùi D·ª± √Ån']} nƒÉm
    {metrics_str}
    """

    try:
        response = client.models.generate_content(
            model=model_name,
            contents=prompt,
            config={"system_instruction": system_prompt}
        )
        return response.text
    except APIError as e:
        return f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API. Chi ti·∫øt l·ªói: {e}"
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

# --- Giao di·ªán Streamlit Ch√≠nh ---

# Kh·ªüi t·∫°o State
if 'extracted_params' not in st.session_state:
    st.session_state.extracted_params = None
if 'df_cash_flow' not in st.session_state:
    st.session_state.df_cash_flow = None
if 'metrics' not in st.session_state:
    st.session_state.metrics = None
if 'ai_analysis' not in st.session_state:
    st.session_state.ai_analysis = None


# --- 1. Upload File Word ---
st.subheader("1. T·∫£i l√™n File Word (.docx) ch·ª©a Ph∆∞∆°ng √°n Kinh doanh")
uploaded_file = st.file_uploader(
    "Vui l√≤ng t·∫£i file Word (.docx). File n√™n ch·ª©a c√°c th√¥ng tin v·ªÅ v·ªën ƒë·∫ßu t∆∞, doanh thu, chi ph√≠, tu·ªïi th·ªç, WACC, v√† thu·∫ø.",
    type=['docx']
)

if uploaded_file:
    # --- N√∫t L·ªçc D·ªØ li·ªáu ---
    if st.button("Tr√≠ch xu·∫•t D·ªØ li·ªáu T√†i ch√≠nh b·∫±ng AI (B∆∞·ªõc 1)", type="primary"):
        with st.spinner('ƒêang ƒë·ªçc file v√† g·ª≠i n·ªôi dung cho AI tr√≠ch xu·∫•t...'):
            document_text = extract_text_from_docx(uploaded_file)

            if document_text:
                params, message = ai_extract_financial_parameters(document_text, API_KEY)
                
                if params:
                    st.session_state.extracted_params = params
                    # Sau khi tr√≠ch xu·∫•t th√†nh c√¥ng, t√≠nh to√°n lu√¥n D√≤ng ti·ªÅn v√† Ch·ªâ s·ªë
                    df_cf, metrics = build_cash_flow_and_calculate_metrics(params)
                    st.session_state.df_cash_flow = df_cf
                    st.session_state.metrics = metrics
                    st.success(f"{message} ƒê√£ s·∫µn s√†ng ƒë·ªÉ xem k·∫øt qu·∫£.")
                else:
                    st.session_state.extracted_params = None
                    st.error(f"Tr√≠ch xu·∫•t th·∫•t b·∫°i: {message}")
            else:
                st.session_state.extracted_params = None

# --- Hi·ªÉn th·ªã K·∫øt qu·∫£ n·∫øu ƒë√£ tr√≠ch xu·∫•t ---
if st.session_state.extracted_params:
    params = st.session_state.extracted_params
    
    st.markdown("---")
    st.subheader("Tr√≠ch xu·∫•t D·ªØ li·ªáu T√†i ch√≠nh Th√†nh c√¥ng (Task 1)")
    
    col_params_1, col_params_2, col_params_3 = st.columns(3)
    
    with col_params_1:
        st.metric("V·ªën ƒê·∫ßu t∆∞ (I‚ÇÄ)", f"{params['V·ªën_ƒê·∫ßu_T∆∞']:,.0f}")
        st.metric("Doanh thu H√†ng nƒÉm", f"{params['Doanh_Thu_H√†ng_NƒÉm']:,.0f}")
    with col_params_2:
        st.metric("D√≤ng ƒë·ªùi D·ª± √°n (N)", f"{params['D√≤ng_ƒê·ªùi_D·ª±_√Ån']} nƒÉm")
        st.metric("Chi ph√≠ H√†ng nƒÉm", f"{params['Chi_Ph√≠_H√†ng_NƒÉm']:,.0f}")
    with col_params_3:
        st.metric("WACC", f"{params['WACC']:.2%}")
        st.metric("Thu·∫ø su·∫•t (T)", f"{params['Thu·∫ø_Su·∫•t']:.0%}")
        
    st.markdown("---")
    
    # --- X√¢y d·ª±ng B·∫£ng D√≤ng Ti·ªÅn (Task 2) ---
    st.subheader("2. B·∫£ng D√≤ng ti·ªÅn R√≤ng (NCF) c·ªßa D·ª± √°n (Task 2)")
    df_cf = st.session_state.df_cash_flow
    
    # ƒê·ªãnh d·∫°ng hi·ªÉn th·ªã
    st.dataframe(df_cf.style.format({
        col: '{:,.0f}' for col in df_cf.columns
    }), use_container_width=True)
    
    st.info("NCF: D√≤ng ti·ªÅn r√≤ng c·ªßa d·ª± √°n (Net Cash Flow).")
    st.markdown("---")
    
    # --- T√≠nh to√°n Ch·ªâ s·ªë ƒê√°nh gi√° (Task 3) ---
    st.subheader("3. C√°c Ch·ªâ s·ªë ƒê√°nh gi√° Hi·ªáu qu·∫£ D·ª± √°n (Task 3)")
    metrics = st.session_state.metrics
    
    col_metrics_1, col_metrics_2, col_metrics_3, col_metrics_4 = st.columns(4)
    
    with col_metrics_1:
        st.metric("Gi√° tr·ªã Hi·ªán t·∫°i R√≤ng (NPV)", f"{metrics['NPV']:,.0f}")
    with col_metrics_2:
        # N·∫øu IRR l√† NaN, hi·ªÉn th·ªã 'N/A'
        irr_value = f"{metrics['IRR']:.2%}" if not np.isnan(metrics['IRR']) else "N/A"
        st.metric("T·ª∑ su·∫•t Ho√†n v·ªën N·ªôi b·ªô (IRR)", irr_value)
    with col_metrics_3:
        st.metric("Th·ªùi gian Ho√†n v·ªën (PP)", f"{metrics['PP']:.2f} nƒÉm")
    with col_metrics_4:
        st.metric("Th·ªùi gian Ho√†n v·ªën c√≥ Chi·∫øt kh·∫•u (DPP)", f"{metrics['DPP']:.2f} nƒÉm")

    st.markdown("---")

    # --- Y√™u c·∫ßu AI Ph√¢n t√≠ch (Task 4) ---
    st.subheader("4. Ph√¢n t√≠ch C√°c Ch·ªâ s·ªë Hi·ªáu qu·∫£ D·ª± √°n (AI) (Task 4)")
    
    if st.button("Y√™u c·∫ßu AI Ph√¢n t√≠ch Hi·ªáu qu·∫£ D·ª± √°n", key="ai_analysis_btn"):
        with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'):
            ai_result = ai_analyze_metrics(metrics, API_KEY)
            st.session_state.ai_analysis = ai_result
            
    if st.session_state.ai_analysis:
        st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**")
        st.info(st.session_state.ai_analysis)

# Footer
st.markdown("---")
st.caption("L∆∞u √Ω: ·ª®ng d·ª•ng gi·∫£ ƒë·ªãnh doanh thu/chi ph√≠ kh√¥ng ƒë·ªïi v√† kh·∫•u hao ƒë∆∞·ªùng th·∫≥ng. WACC v√† Thu·∫ø su·∫•t l√† c√°c t·ª∑ l·ªá c·ªë ƒë·ªãnh.")
